  
1.select lots of crawling code encapsulated as a class in paqu.py file to make main code cleaner

2.add paqu.py encapsulated code as a Spider() class

3.add Novel_Type ENUM and Novel_Info ENUM to make code more understanding

4.add multithreading to crawl the www.quanshuwang.com

5.add save_pic function

 can save all novel pictures in the path

 every novel has their own folder to save picture(now just save picture...)
6.get information return a list, is easy to add the connect mysql function

※A Dangerious Bug——crawd 1,2,3,4,6 page, novels with repetition ,maybe novel_url has some issues.
